{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f9ae5b",
   "metadata": {},
   "source": [
    "# Langgraph Bigtool + Long Memory's Similarity Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820f5435",
   "metadata": {},
   "source": [
    "## Load MCP Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def load_mcp_servers(config_path):\n",
    "    \"\"\"\n",
    "    Load MCP server definitions from a JSON config file.\n",
    "    Expects a top-level 'mcpServers' dict in the config.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(config_path):\n",
    "        raise FileNotFoundError(f\"Config file not found: {config_path}\")\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "    servers = config.get(\"mcpServers\", {})\n",
    "    # Optionally add default transports if missing\n",
    "    for name, server in servers.items():\n",
    "        if \"command\" in server and \"transport\" not in server:\n",
    "            server[\"transport\"] = \"stdio\"\n",
    "        if \"url\" in server and \"transport\" not in server:\n",
    "            server[\"transport\"] = \"streamable_http\"\n",
    "    return servers\n",
    "\n",
    "mcp_servers = load_mcp_servers(\"./mcp_config.json\")\n",
    "mcp_servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e33d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "client = MultiServerMCPClient(mcp_servers)\n",
    "mcp_tools = await client.get_tools()\n",
    "\n",
    "print(f\"Loaded {len(mcp_tools)} tools.\\n\")\n",
    "print(f\"Example of a tool:\\n{mcp_tools[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6241479",
   "metadata": {},
   "source": [
    "## Define Tool Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "EXCLUDED_TOOLS = {\"search_repositories\"}\n",
    "\n",
    "# Create registry of tools. This is a dict mapping\n",
    "# identifiers to tool instances.\n",
    "tool_registry = {\n",
    "    str(uuid.uuid4()): tool\n",
    "    for tool in mcp_tools\n",
    "    if tool.name not in EXCLUDED_TOOLS\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6805f4e6",
   "metadata": {},
   "source": [
    "## Init Long Memory with Tools definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975af6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import init_embeddings\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Index tool names and descriptions in the LangGraph\n",
    "# Store. Here we use a simple in-memory store.\n",
    "embeddings = init_embeddings(\"openai:text-embedding-3-small\")\n",
    "\n",
    "store = InMemoryStore(\n",
    "    index={\n",
    "        \"embed\": embeddings,\n",
    "        \"dims\": 1536,\n",
    "        \"fields\": [\"description\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "for tool_id, tool in tool_registry.items():\n",
    "    store.put(\n",
    "        (\"tools\",),\n",
    "        tool_id,\n",
    "        {\n",
    "            \"description\": f\"{tool.name}: {tool.description}\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "store.search((\"tools\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08391ff",
   "metadata": {},
   "source": [
    "### testing RAG for tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f936d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve relevant tools based on user query\n",
    "relevant_tools = store.search(\n",
    "    (\"tools\",),\n",
    "    query=\"I want to create a GitHub issue\",\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "for tool in relevant_tools:\n",
    "    print(f\"- {tool}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf1811",
   "metadata": {},
   "source": [
    "btw you can also use this technique for Dynamic Tools Selection (previous lesson) instead of LLM categorizations via structured output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf9b69",
   "metadata": {},
   "source": [
    "## Create Bigtool Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a64e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_bigtool import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from tools import draw_mermaid_png\n",
    "\n",
    "# Initialize agent\n",
    "model = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "builder = create_agent(model, tool_registry, limit=5)\n",
    "bigtool_agent = builder.compile(store=store)\n",
    "\n",
    "draw_mermaid_png(bigtool_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f50aae",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea36c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from textwrap import dedent\n",
    "\n",
    "user_query = \"\"\"\n",
    "Create a new issue in the langgraph-advanced repository in my account with the following details:\n",
    "\n",
    "Title: \"Add documentation for bigtool example\"\n",
    "\n",
    "Description: \n",
    "This issue tracks the need to document the bigtool pattern for handling large numbers of tools.\n",
    "The documentation should cover:\n",
    "- How semantic search is used to retrieve relevant tools\n",
    "- The difference between bigtool and standard tool binding\n",
    "- Best practices for tool descriptions to improve retrieval accuracy\n",
    "- Example use cases demonstrating the pattern\n",
    "\n",
    "This will help users understand when and how to use the bigtool library effectively.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "result = await bigtool_agent.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=user_query)]}\n",
    ")\n",
    "\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b5a0ef",
   "metadata": {},
   "source": [
    "### What the LLM Sees (Tool Schema) and why this is less favorable way\n",
    "\n",
    "```\n",
    "{\n",
    "  \"name\": \"retrieve_tools\",\n",
    "  \"description\": \"Retrieve relevant tools based on a search query.\",\n",
    "  \"parameters\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"query\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"Search query\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\"query\"]\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7933965",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "\n",
    "**1. Handling Large Numbers of Tools in LangGraph**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#handle-large-numbers-of-tools\n",
    "\n",
    "→ Guide to managing agents with many tools using semantic search and filtering strategies to reduce context size and improve tool selection accuracy.\n",
    "\n",
    "**2. LangGraph BigTool: GitHub Repository**\n",
    "\n",
    "https://github.com/langchain-ai/langgraph-bigtool\n",
    "\n",
    "→ Official package for semantic tool retrieval in LangGraph, enabling agents to work with large tool sets by dynamically selecting relevant tools based on query similarity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
