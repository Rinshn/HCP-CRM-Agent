{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ed7c41f",
   "metadata": {},
   "source": [
    "# Standardizing HITL Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b7233",
   "metadata": {},
   "source": [
    "## Let's combine previous examples with Question and HITL approval for risky tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9a6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import yfinance as yf\n",
    "from pprint import pformat\n",
    "\n",
    "from langgraph.types import interrupt\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "\n",
    "@tool(\"lookup_stock\")\n",
    "def lookup_stock_symbol(company_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a company name to its stock symbol using a financial API.\n",
    "\n",
    "    Parameters:\n",
    "        company_name (str): The full company name (e.g., 'Tesla').\n",
    "\n",
    "    Returns:\n",
    "        str: The stock symbol (e.g., 'TSLA') or an error message.\n",
    "    \"\"\"\n",
    "    api_url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": \"SYMBOL_SEARCH\",\n",
    "        \"keywords\": company_name,\n",
    "        \"apikey\": \"your_alphavantage_api_key\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"bestMatches\" in data and data[\"bestMatches\"]:\n",
    "        return data[\"bestMatches\"][0][\"1. symbol\"]\n",
    "    else:\n",
    "        return f\"Symbol not found for {company_name}.\"\n",
    "\n",
    "\n",
    "@tool(\"fetch_stock_data\")\n",
    "def fetch_stock_data_raw(stock_symbol: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetches comprehensive stock data for a given symbol and returns it as a combined dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        stock_symbol (str): The stock ticker symbol (e.g., 'TSLA').\n",
    "        period (str): The period to analyze (e.g., '1mo', '3mo', '1y').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary combining general stock info and historical market data.\n",
    "    \"\"\"\n",
    "    period = \"1mo\"\n",
    "    try:\n",
    "        stock = yf.Ticker(stock_symbol)\n",
    "\n",
    "        # Retrieve general stock info and historical market data\n",
    "        stock_info = stock.info  # Basic company and stock data\n",
    "        stock_history = stock.history(period=period).to_dict()  # Historical OHLCV data\n",
    "\n",
    "        # Combine both into a single dictionary\n",
    "        combined_data = {\n",
    "            \"stock_symbol\": stock_symbol,\n",
    "            \"info\": stock_info,\n",
    "            \"history\": stock_history\n",
    "        }\n",
    "\n",
    "        return pformat(combined_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error fetching stock data for {stock_symbol}: {str(e)}\"}\n",
    "\n",
    "\n",
    "@tool\n",
    "def place_order(\n",
    "    symbol: str,\n",
    "    action: str,\n",
    "    shares: int,\n",
    "    limit_price: float,\n",
    "    order_type: str = \"limit\",\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Execute a stock order.\n",
    "\n",
    "    Parameters:\n",
    "    - symbol: Ticker\n",
    "    - action: \"buy\" or \"sell\"\n",
    "    - shares: Number of shares to trade (pre-computed by the agent)\n",
    "    - limit_price: Limit price per share\n",
    "    - order_type: Order type, default \"limit\"\n",
    "\n",
    "    Returns:\n",
    "    - status: Execution result (simulated)\n",
    "    - symbol\n",
    "    - shares\n",
    "    - limit_price\n",
    "    - total_spent\n",
    "    - type: Order type used\n",
    "    - action\n",
    "    \"\"\"\n",
    "    total_spent = round(int(shares) * limit_price, 2)\n",
    "    return {\n",
    "        \"status\": \"filled\",\n",
    "        \"symbol\": symbol,\n",
    "        \"shares\": int(shares),\n",
    "        \"limit_price\": limit_price,\n",
    "        \"total_spent\": total_spent,\n",
    "        \"type\": order_type,\n",
    "        \"action\": action,\n",
    "    }\n",
    "\n",
    "\n",
    "@tool\n",
    "def ask_question(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Asks a human a question and waits for their response using Human-in-the-Loop (HITL).\n",
    "    \n",
    "    This tool interrupts the agent's execution to collect human input, then resumes\n",
    "    with the human's answer. Use this when you need clarification, approval, or\n",
    "    information that only the human can provide.\n",
    "    \n",
    "    Parameters:\n",
    "        question (str): The question to ask the human. Be specific and clear.\n",
    "        \n",
    "    Returns:\n",
    "        str: The human's response to the question.\n",
    "        \n",
    "    Example:\n",
    "        >>> ask_question(\"What is your preferred investment budget for this trade?\")\n",
    "        # Agent pauses here, waiting for human input\n",
    "        # Returns: \"$5000\" (or whatever the human responds)\n",
    "    \"\"\"\n",
    "    # Interrupt execution and send the question to the human\n",
    "    # The value passed to interrupt() is what the human sees\n",
    "    response = interrupt({\"question\": question})\n",
    "    return {\n",
    "        \"user's response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c1254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from langchain_core.tools import BaseTool, tool\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "def add_approval(main_tool: Callable | BaseTool) -> BaseTool:\n",
    "    \"\"\"Wrap a tool to support human-in-the-loop review.\"\"\"\n",
    "    if not isinstance(main_tool, BaseTool):\n",
    "        main_tool = tool(main_tool)\n",
    "\n",
    "    @tool(  \n",
    "        main_tool.name,\n",
    "        description=main_tool.description,\n",
    "        args_schema=main_tool.args_schema\n",
    "    )\n",
    "    def call_main_tool_with_hitl(config: RunnableConfig, **tool_input):\n",
    "        decision = interrupt({\n",
    "            \"awaiting\": main_tool.name,\n",
    "            \"args\": tool_input\n",
    "        })\n",
    "\n",
    "        # tool approved\n",
    "        if isinstance(decision, dict) and decision.get(\"approved\"):\n",
    "            return main_tool.invoke(tool_input, config)\n",
    "\n",
    "        # tool rejected\n",
    "        return \"Cancelled by human. Continue without executing that tool and provide next steps.\"\n",
    "        \n",
    "\n",
    "    return call_main_tool_with_hitl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284596d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a financial advisor assistant. Use the provided tools to ground your answers\n",
    "in up-to-date market data. Be concise, factual, and risk-aware.\n",
    "\n",
    "Be decisive: when you have sufficient information to act, proceed with tool calls without\n",
    "asking for confirmation. Only if information is missing or uncertain, ask a concise \n",
    "clarifying question.\n",
    "\n",
    "When preparing or describing actions, include appropriate parameters (e.g., symbol, shares,\n",
    "limit price, budgets) based on available data. Do not fabricate numbers or facts.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from tools import draw_mermaid_png\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[lookup_stock_symbol, fetch_stock_data_raw, add_approval(place_order), ask_question],\n",
    "    prompt=system_message,\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "draw_mermaid_png(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55435291",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": str(uuid.uuid4())\n",
    "    }\n",
    "}\n",
    "\n",
    "response = agent.invoke({\"messages\": [HumanMessage(content=\"Buy some Tesla stock at the current price.\")]}, config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ae933",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"__interrupt__\" in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828697d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "interrupts = response[\"__interrupt__\"]\n",
    "interrupts[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07acea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "user_response = \"I want to invest $1000 maximum\"\n",
    "\n",
    "response = agent.invoke(Command(resume=user_response), config=config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44383ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"__interrupt__\" in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a7ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "interrupts = response[\"__interrupt__\"]\n",
    "interrupts[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04df8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "user_response = {\"approved\": True}\n",
    "\n",
    "response = agent.invoke(Command(resume=user_response), config=config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1f3399",
   "metadata": {},
   "source": [
    "### Problem: the format of requests & responses is different from interruption to interruption\n",
    "\n",
    "- `user_response = \"I want to invest $1000 maximum\"` converted under the hood to `{\"user's response\": \"I want to invest $1000 maximum\"}`\n",
    "\n",
    "- `user_response = {\"approved\": True}`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe7d1d1",
   "metadata": {},
   "source": [
    "## Unifying the interruption/ response formats\n",
    "\n",
    "let's reuse standard LangGraph's `HumanInterrupt` and `HumanResponse`\n",
    "\n",
    "### HumanInterrupt\n",
    "\n",
    "- `action_request: ActionRequest` The specific action being requested from the human\n",
    "- `config: HumanInterruptConfig` Configuration defining what actions are allowed\n",
    "- `description: str | None` Optional detailed description of what input is needed\n",
    "\n",
    "#### ActionRequest\n",
    "\n",
    "- `action: str`\tThe type or name of action being requested (e.g., \"Approve XYZ action\")\n",
    "- `args: dict`\tKey-value pairs of arguments needed for the action\n",
    "\n",
    "#### HumanInterruptConfig\n",
    "\n",
    "- `allow_ignore: bool`\tWhether the human can choose to ignore/skip the current step\n",
    "- `allow_respond: bool` Whether the human can provide a text response/feedback\n",
    "- `allow_edit: bool` Whether the human can edit the provided content/state\n",
    "- `allow_accept: bool` Whether the human can accept/approve the current state\n",
    "\n",
    "### HumanResponse\n",
    "\n",
    "- `type:\tLiteral['accept', 'ignore', 'response', 'edit']`\tThe type of response:\n",
    "    - `accept`: Approves the current state without changes \n",
    "    - `ignore`: Skips/ignores the current step \n",
    "    - `response`: Provides text feedback or instructions \n",
    "    - `edit`: Modifies the current state/content\n",
    "- `args: None | str | ActionRequest`\tThe response payload: \n",
    "    - `None`: For ignore/accept actions \n",
    "    - `str`: For text responses \n",
    "    - `ActionRequest`: For edit actions with updated content\n",
    "\n",
    "\n",
    "### Example\n",
    "\n",
    "```python\n",
    "request = HumanInterrupt(\n",
    "    action_request=ActionRequest(\n",
    "        action=tool_call[\"name\"]\n",
    "        args=tool_call[\"args\"]\n",
    "    ),\n",
    "    config=HumanInterruptConfig(\n",
    "        allow_ignore=True,\n",
    "        allow_respond=False,\n",
    "        allow_edit=True,\n",
    "        allow_accept=True\n",
    "    ),\n",
    "    description=\"Please approve the tool before execution\"\n",
    ")\n",
    "```\n",
    "\n",
    "```python\n",
    "response = HumanInterrupt(\n",
    "    type=\"accept\",\n",
    "    args=None\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303f9c37",
   "metadata": {},
   "source": [
    "## Use LangGraph's `HumanInterrupt` and `HumanResponse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa963057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt.interrupt import HumanInterrupt, HumanResponse, HumanInterruptConfig, ActionRequest\n",
    "\n",
    "@tool\n",
    "def ask_question(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Asks a human a question and waits for their response using Human-in-the-Loop (HITL).\n",
    "    \n",
    "    This tool interrupts the agent's execution to collect human input, then resumes\n",
    "    with the human's answer. Use this when you need clarification, approval, or\n",
    "    information that only the human can provide.\n",
    "    \n",
    "    Parameters:\n",
    "        question (str): The question to ask the human. Be specific and clear.\n",
    "        \n",
    "    Returns:\n",
    "        str: The human's response to the question.\n",
    "        \n",
    "    Example:\n",
    "        >>> ask_question(\"What is your preferred investment budget for this trade?\")\n",
    "        # Agent pauses here, waiting for human input\n",
    "        # Returns: \"$5000\" (or whatever the human responds)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create standardized interrupt request\n",
    "    request = HumanInterrupt(\n",
    "        action_request=ActionRequest(\n",
    "            action=\"ask_question\",  # The tool name\n",
    "            args={\"question\": question}  # The tool arguments\n",
    "        ),\n",
    "        config=HumanInterruptConfig(\n",
    "            allow_ignore=True,      # User can skip the question\n",
    "            allow_respond=True,     # User can provide text response\n",
    "            allow_edit=False,       # User cannot edit the question\n",
    "            allow_accept=False      # No accept action for questions\n",
    "        ),\n",
    "        description=f\"Please answer the following question: {question}\"\n",
    "    )\n",
    "    \n",
    "    # Send interrupt and wait for response\n",
    "    response = interrupt(request)\n",
    "    \n",
    "    # Handle different response types\n",
    "    if response[\"type\"] == \"response\":\n",
    "        # User provided text response\n",
    "        return response[\"args\"]  # This is the string response\n",
    "    elif response[\"type\"] == \"ignore\":\n",
    "        # User chose to skip\n",
    "        return \"User chose not to answer this question.\"\n",
    "    else:\n",
    "        # Unexpected response type\n",
    "        return f'Unexpected response type: {response[\"type\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f09e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from langchain_core.tools import BaseTool, tool\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.types import interrupt\n",
    "from langgraph.prebuilt.interrupt import HumanInterrupt, HumanResponse, HumanInterruptConfig, ActionRequest\n",
    "\n",
    "def add_approval(main_tool: Callable | BaseTool, allow_edit: bool = False) -> BaseTool:\n",
    "    \"\"\"\n",
    "    Wrap a tool to support human-in-the-loop review using standardized format.\n",
    "    \n",
    "    Args:\n",
    "        main_tool: The tool to wrap with HITL approval\n",
    "        allow_edit: Whether to allow editing tool arguments (default: False)\n",
    "        \n",
    "    Note on allow_edit:\n",
    "        - False (recommended): User can only approve or reject. Safer for production.\n",
    "          If user wants changes, they reject and instruct the agent differently.\n",
    "        - True (educational): User can edit arguments, but this can break agent reasoning\n",
    "          if they change the action completely (e.g., Tesla → Microsoft).\n",
    "          Use with caution and consider validation in production.\n",
    "    \"\"\"\n",
    "    if not isinstance(main_tool, BaseTool):\n",
    "        main_tool = tool(main_tool)\n",
    "\n",
    "    @tool(  \n",
    "        main_tool.name,\n",
    "        description=main_tool.description,\n",
    "        args_schema=main_tool.args_schema\n",
    "    )\n",
    "    def call_main_tool_with_hitl(config: RunnableConfig, **tool_input):\n",
    "        # Create standardized interrupt request\n",
    "        request = HumanInterrupt(\n",
    "            action_request=ActionRequest(\n",
    "                action=main_tool.name,  # The tool being called\n",
    "                args=tool_input         # The tool arguments\n",
    "            ),\n",
    "            config=HumanInterruptConfig(\n",
    "                allow_ignore=True,      # User can skip/reject the tool\n",
    "                allow_respond=False,    # No text response needed\n",
    "                allow_edit=allow_edit,  # Configurable: allow editing args\n",
    "                allow_accept=True       # User can approve the tool\n",
    "            ),\n",
    "            description=f\"Please review and approve the '{main_tool.name}' tool call\"\n",
    "        )\n",
    "        \n",
    "        # Send interrupt and wait for response\n",
    "        response = interrupt(request)\n",
    "        \n",
    "        # Handle different response types\n",
    "        if response[\"type\"] == \"accept\":\n",
    "            # Tool approved - execute with original args\n",
    "            return main_tool.invoke(tool_input, config)\n",
    "        \n",
    "        elif response[\"type\"] == \"edit\":\n",
    "            # Tool approved with edited args\n",
    "            # WARNING: Edited args may break agent's reasoning if changed significantly\n",
    "            edited_action: ActionRequest = response[\"args\"]\n",
    "            return main_tool.invoke(edited_action.args, config)\n",
    "        \n",
    "        elif response[\"type\"] == \"ignore\":\n",
    "            # Tool rejected\n",
    "            return \"Cancelled by human. Continue without executing that tool and provide next steps.\"\n",
    "        \n",
    "        else:\n",
    "            # Unexpected response type\n",
    "            return f'Unexpected response type: {response[\"type\"]}. Tool not executed.'\n",
    "        \n",
    "\n",
    "    return call_main_tool_with_hitl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351124aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from tools import draw_mermaid_png\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[lookup_stock_symbol, fetch_stock_data_raw, add_approval(place_order), ask_question],\n",
    "    prompt=system_message,\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "draw_mermaid_png(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c612dc",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a1256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": str(uuid.uuid4())\n",
    "    }\n",
    "}\n",
    "\n",
    "response = agent.invoke({\"messages\": [HumanMessage(content=\"Buy some Tesla stock at the current price.\")]}, config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62620626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"__interrupt__\" in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "interrupts = response[\"__interrupt__\"]\n",
    "interrupts[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41541d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "from langgraph.prebuilt.interrupt import HumanResponse\n",
    "\n",
    "user_response = HumanResponse(\n",
    "    type=\"response\",\n",
    "    args=\"I want to invest $1000 maximum\"\n",
    ")\n",
    "\n",
    "response = agent.invoke(Command(resume=user_response), config=config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"__interrupt__\" in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0366941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interrupts = response[\"__interrupt__\"]\n",
    "interrupts[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2e0ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "user_response = {\"type\": \"accept\", \"args\": None}\n",
    "\n",
    "response = agent.invoke(Command(resume=user_response), config=config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee4e461",
   "metadata": {},
   "source": [
    "## Testing with Agent Chat UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f50e86a",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "\n",
    "**1. HumanInterrupt API Reference**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.interrupt.HumanInterrupt\n",
    "\n",
    "→ Documentation for the HumanInterrupt class used to pause agent execution and emit interrupt events for human review.\n",
    "\n",
    "**2. HumanResponse API Reference**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.interrupt.HumanResponse\n",
    "\n",
    "→ Reference for crafting structured human responses that resume execution after an interrupt, including payload formats and fields.\n",
    "\n",
    "**3. HumanInterruptConfig API Reference**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.interrupt.HumanInterruptConfig\n",
    "\n",
    "→ Configuration schema for HumanInterrupt, detailing options like timeout behavior, metadata, and resume handling.\n",
    "\n",
    "**4. ActionRequest API Reference**\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.interrupt.ActionRequest\n",
    "\n",
    "→ Specification for ActionRequest objects that encapsulate tool or action execution details when an interrupt occurs.\n",
    "\n",
    "**5. LangChain JS UI: Tool Visualization Guide**\n",
    "\n",
    "https://docs.langchain.com/oss/javascript/langchain/ui#tool-visualization\n",
    "\n",
    "→ Guide to visualizing tool calls and agent traces in the LangChain JavaScript UI, useful for monitoring human-in-the-loop workflows.\n",
    "\n",
    "**6. AgentChat Playground**\n",
    "\n",
    "https://agentchat.vercel.app/\n",
    "\n",
    "→ Interactive web demo for experimenting with LangChain agents, showcasing UI patterns for interrupts and human feedback loops."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
